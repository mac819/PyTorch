{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=/Users/mayankanand/Documents/pytorch/images/linear_layer.png height=300 width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19., 20., 21., 22., 23.],\n",
       "        [24., 25., 26., 27., 28., 29., 30., 31.],\n",
       "        [32., 33., 34., 35., 36., 37., 38., 39.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets take an input data with batch_size of 16 and with feature shape of 8\n",
    "input_tensor = torch.arange(128, dtype=torch.float).view(16, 8)\n",
    "input_tensor[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=2, bias=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we have to make a prediction for two classes then output layer should have two nodes.\n",
    "linear_layers = nn.Linear(8, 2, dtype=torch.float)\n",
    "linear_layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(8, 2, dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight',\n",
       "              tensor([[-0.1418, -0.3059,  0.0574, -0.2477,  0.1296,  0.3349, -0.3096, -0.1380],\n",
       "                      [ 0.3129, -0.2057,  0.3207,  0.1450, -0.3323,  0.2019,  0.3079,  0.1525]])),\n",
       "             ('linear_layer.bias', tensor([ 0.0578, -0.1919]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearModel()\n",
    "linear_model.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sigmoid` activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid() # Activation function applied on output coming after linear computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8136e-01, 9.6352e-01],\n",
      "        [1.5384e-03, 9.9997e-01],\n",
      "        [1.0715e-05, 1.0000e+00],\n",
      "        [7.4525e-08, 1.0000e+00],\n",
      "        [5.1831e-10, 1.0000e+00],\n",
      "        [3.6047e-12, 1.0000e+00],\n",
      "        [2.5070e-14, 1.0000e+00],\n",
      "        [1.7436e-16, 1.0000e+00],\n",
      "        [1.2126e-18, 1.0000e+00],\n",
      "        [8.4337e-21, 1.0000e+00],\n",
      "        [5.8655e-23, 1.0000e+00],\n",
      "        [4.0793e-25, 1.0000e+00],\n",
      "        [2.8371e-27, 1.0000e+00],\n",
      "        [1.9731e-29, 1.0000e+00],\n",
      "        [1.3723e-31, 1.0000e+00],\n",
      "        [9.5440e-34, 1.0000e+00]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Xo = linear_model(input_tensor)\n",
    "y = sigmoid(Xo)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=/Users/mayankanand/Documents/pytorch/images/rnn_flow.png height=400 width=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RNN layer, there are three weight matrix.\n",
    "1. First is for input at each timestamp\n",
    "2. Second is for hidden state layers coming from pervious timestamp\n",
    "3. Third is for the output coming after applying activation function to the linear computation\n",
    "\n",
    "These weights are shared across all the other timestamp(t)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take an example where input data is sequence of `32 tokens` with `embeddings size of 128`. At each timestamp it gives output of `16 nodes`\n",
    "- Output node count can be configured based on use-case. E.g, \n",
    "    - For machine translation, output could be vocab_size\n",
    "    - In case of sentiment analysis, output could be a single node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "# Defining learning parameters\n",
    "wi = nn.Linear(128, 64, dtype=torch.float)\n",
    "wh = nn.Linear(64, 64, dtype=torch.float)\n",
    "wo = nn.Linear(64, 16, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Generating a sequence with 32 tokens and it's embedding with batch_size of 8\n",
    "input_seq = torch.rand(8, 32, 128, dtype=torch.float)\n",
    "print(input_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1233, 0.7378, 0.7926,  ..., 0.2149, 0.1500, 0.5144],\n",
      "        [0.5717, 0.6686, 0.7401,  ..., 0.9193, 0.2378, 0.0434],\n",
      "        [0.4646, 0.1059, 0.3264,  ..., 0.0427, 0.7981, 0.5636],\n",
      "        ...,\n",
      "        [0.5659, 0.6944, 0.1545,  ..., 0.3293, 0.1927, 0.9063],\n",
      "        [0.5424, 0.6935, 0.6207,  ..., 0.2686, 0.2356, 0.7422],\n",
      "        [0.3006, 0.9047, 0.2034,  ..., 0.0481, 0.6002, 0.8851]])\n",
      "torch.Size([8, 128])\n"
     ]
    }
   ],
   "source": [
    "for i in range(input_seq.shape[1]):\n",
    "    print(input_seq[:, i, :])\n",
    "    print(input_seq[:, i, :].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1233, 0.7378, 0.7926,  ..., 0.2149, 0.1500, 0.5144],\n",
       "        [0.5717, 0.6686, 0.7401,  ..., 0.9193, 0.2378, 0.0434],\n",
       "        [0.4646, 0.1059, 0.3264,  ..., 0.0427, 0.7981, 0.5636],\n",
       "        ...,\n",
       "        [0.5659, 0.6944, 0.1545,  ..., 0.3293, 0.1927, 0.9063],\n",
       "        [0.5424, 0.6935, 0.6207,  ..., 0.2686, 0.2356, 0.7422],\n",
       "        [0.3006, 0.9047, 0.2034,  ..., 0.0481, 0.6002, 0.8851]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward propagation\n",
    "# Initializing initial hidden input\n",
    "init_hidden_variable = torch.rand(8, 64)\n",
    "\n",
    "input_at_t0 = input_seq[:, 0, :]\n",
    "input_at_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function\n",
    "tanh_function = nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 16])\n"
     ]
    }
   ],
   "source": [
    "# Linear addition of input with wi\n",
    "xit = wi(input_at_t0)\n",
    "print(xit.shape)\n",
    "\n",
    "# Adding hidden state value to x0t\n",
    "xh = torch.add(xit, init_hidden_variable)\n",
    "print(xh.shape)\n",
    "\n",
    "# Applying Activation function\n",
    "xht = tanh_function(xh)\n",
    "print(xht.shape)\n",
    "\n",
    "# Output Linear computation\n",
    "xo = wo(xht)\n",
    "print(xo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15]]) tensor([0.7922, 0.3760, 0.9716, 0.9059, 0.4850, 0.0643, 0.7914, 0.4331])\n",
      "tensor([[ 0.7922,  1.3760,  2.9716,  3.9059,  4.4850,  5.0643,  6.7914,  7.4331],\n",
      "        [ 8.7922,  9.3760, 10.9716, 11.9059, 12.4850, 13.0643, 14.7914, 15.4331]])\n"
     ]
    }
   ],
   "source": [
    "test_xit = torch.arange(16).view(2, 8)\n",
    "test_hidden_tensor = torch.rand(8)\n",
    "print(test_xit, test_hidden_tensor)\n",
    "print(torch.add(test_hidden_tensor, test_xit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Model\n",
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.wi = nn.Linear(128, 64)\n",
    "        self.wh = nn.Linear(64, 64)\n",
    "        self.wo = nn.Linear(64, 16)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.init_hidden_variable = torch.rand(64) # Values of this tensor will get broadcasted along batch\n",
    "        self.hidden_tensor_list = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        timestamp_count = x.shape[1]\n",
    "        output_tensor = []\n",
    "        for i in range(timestamp_count):\n",
    "            xit = wi(x[:, i, :])\n",
    "            # xit = torch.matmul(wi, x[:, i, :])\n",
    "            if i == 0:\n",
    "                xh = torch.add(xit, self.init_hidden_variable)\n",
    "            else:\n",
    "                try:\n",
    "                    xh = torch.add(xit, self.hidden_tensor_list.pop())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "            xht = self.tanh(xh)\n",
    "            self.hidden_tensor_list.append(xht)\n",
    "            xot = self.wo(xht)\n",
    "\n",
    "            output_tensor.append(xot[:, None, :])\n",
    "\n",
    "        return torch.concat(output_tensor, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNNModel()\n",
    "output_tensor = rnn_model(input_seq)\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32, 128]) torch.Size([8, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "print(input_seq.shape, output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
